# An Inquiry into Context, Memory, and Cognitive Failure in LLMs

This repository is not a product, a framework, or a finished theory.

It is an open cognitive workspace for examining a recurring failure mode in large language models:
what is commonly described as “forgetting” may not be a problem of memory capacity,
but a failure of contextual activation and priority ordering.

This is an inquiry, not a conclusion.

---

## What This Repository Is

- A collection of **observations**, **hypotheses**, and **conceptual probes**
  derived from sustained, real-world interaction with LLMs in long-context,
  multi-document, and goal-evolving scenarios.
- A shared surface for **critical discussion**, **refutation**, and **alternative explanations**.
- An upstream space for ideas that may, or may not, later inform open-source systems
  such as agent-based cognitive scaffolding.

This repository treats thinking itself as a mutable artifact.

---

## What This Repository Is Not

- ❌ A polished academic paper  
- ❌ A benchmark-driven evaluation  
- ❌ A claim of discovering “human-like intelligence”  
- ❌ A proposal ready for engineering implementation  
- ❌ A request for consensus, endorsement, or authority  

If you are looking for certainty, finality, or validation,
this repository will likely be frustrating.

---

## Core Motivation

Contemporary discussions of LLM limitations often default to the concept of “memory”:
context windows, retrieval size, token limits.

However, in practice, many failures exhibit a different pattern:

- Relevant information exists in context
- The model can recover it when explicitly prompted
- The failure appears as *mis-prioritization*, not absence

This raises a different question:

> What if the dominant failure mode is not memory insufficiency,
> but contextual activation collapse and priority drift?

This repository exists to explore that question — and to be proven wrong if necessary.

---

## Structure of the Repository

- **CORE_THESES/**  
  Focused essays, each presenting a single claim, its empirical motivation,
  and clearly stated boundaries of uncertainty.

- **COUNTERPOINTS/**  
  A dedicated space for critiques, refutations, and competing models.
  Strong disagreement is explicitly welcomed.

- **DISCUSSIONS/**  
  Ongoing questions, recurring objections, and unresolved tensions.

- **EVOLUTION_LOG/**  
  A public record of how and why certain positions have changed over time.
  Changing one’s mind is treated as progress, not failure.

---

## Invitation to Engage

You are invited to engage if you want to:

- Examine where current abstractions of “memory” break down
- Explore alternatives to retrieval-centric thinking
- Critique informal theories grounded in real usage rather than benchmarks
- Contribute counterexamples, failures, or better explanations

You are *not* expected to agree.
You are encouraged to challenge.

Silence is less valuable than informed criticism.

---

## On Future Directions

Some ideas explored here may later inform an open-source project tentatively called **“谋小计”**,
focused on agent-based cognitive scaffolding and long-horizon human–AI collaboration.

This repository is upstream of any such effort.
No implementation commitment is implied.

If these ideas eventually contribute to a broader shift in how we think about
knowledge, intelligence, and coordination — regardless of which project realizes it —
that outcome would fulfill the original intent.

---

## License

Unless otherwise noted, the content of this repository is licensed under **CC BY 4.0**.
You are free to reuse, adapt, and critique the ideas presented here, with attribution.

Ideas are shared here to evolve, not to be protected.

